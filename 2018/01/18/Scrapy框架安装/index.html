<!DOCTYPE html>
<html lang="zh-CN">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">



  <meta name="description" content="Scrapy框架安装">




  <meta name="keywords" content="web crawler, environment, Sampwood的One Piece">










  <link rel="alternate" href="/atom.xml" title="Sampwood的One Piece">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.10.1">



<link rel="canonical" href="https://sampwood.github.io/2018/01/18/Scrapy框架安装/">



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css">




  <link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">



<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.10.1">



  



  <script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>








<script>
  window.config = {"title":"Sampwood的One Piece","subtitle":"step by step","description":"Web developer form somewhere","author":"Sampwood","language":"zh-CN","timezone":"Asia/Shanghai","url":"https://sampwood.github.io","root":"/","permalink":":year/:month/:day/:title/","permalink_defaults":null,"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":true,"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"auto_detect":false,"line_number":true,"tab_replace":null,"first_line_number":"always1"},"default_category":"uncategorized","category_map":null,"tag_map":null,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","per_page":0,"pagination_dir":"page","theme":"even","deploy":{"type":"git","repo":"https://github.com/Sampwood/sampwood.github.io.git","branch":"master"},"ignore":[],"index_generator":{"per_page":10,"order_by":"-date","path":""},"jsonContent":{"meta":false,"pages":false,"posts":{"title":true,"date":true,"path":true,"text":false,"raw":false,"content":false,"slug":false,"updated":false,"comments":false,"link":false,"permalink":false,"excerpt":false,"categories":false,"tags":true}},"feed":{"type":"atom","limit":20,"hub":"","content":true,"content_limit":140,"content_limit_delim":"","path":"atom.xml"},"archive_generator":{"per_page":0,"yearly":true,"monthly":true,"daily":false},"category_generator":{"per_page":0},"tag_generator":{"per_page":0},"marked":{"gfm":true,"pedantic":false,"sanitize":false,"tables":true,"breaks":true,"smartLists":true,"smartypants":true},"server":{"port":4000,"log":false,"ip":"0.0.0.0","compress":false,"header":true},"since":2015,"favicon":"/favicon.ico","rss":"default","menu":{"Home":"/","Archives":"/archives/","Tags":"/tags","Categories":"/categories","About":"/about"},"color":"default","mode":"default","toc":true,"fancybox":true,"pjax":true,"copyright":{"enable":true,"license":"<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\">知识共享署名-非商业性使用 4.0 国际许可协议</a>"},"reward":{"enable":false,"qrCode":{"wechat":null,"alipay":null}},"social":{"email":"sampwood@163.com","stack-overflow":null,"twitter":null,"facebook":null,"linkedin":null,"google":null,"github":"https://github.com/sampwood","weibo":null,"zhihu":null,"douban":null,"pocket":null,"tumblr":null,"instagram":null},"leancloud":{"app_id":null,"app_key":null},"baidu_analytics":null,"baidu_verification":null,"google_analytics":null,"google_verification":null,"disqus_shortname":null,"changyan":{"appid":null,"appkey":null},"livere_datauid":null,"version":"2.10.1"};
</script>

    <title> Scrapy框架安装 - Sampwood的One Piece </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Sampwood的One Piece</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            首页
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            归档
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            标签
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            分类
          
        </li>
      </a>
    
      <a href="/about">
        <li class="mobile-menu-item">
          
          
            关于
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Sampwood的One Piece</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              首页
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              归档
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              标签
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              分类
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/about">
            
            
              关于
            
          </a>
        </li>
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Scrapy框架安装
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-01-18
        </span>
        
          <span class="post-category">
            
              <a href="/categories/coding/">coding</a>
            
              <a href="/categories/coding/python/">python</a>
            
          </span>
        
        
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Scrapy安装"><span class="toc-text">Scrapy安装</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#失败案例"><span class="toc-text">失败案例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#成功方案"><span class="toc-text">成功方案</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#文章"><span class="toc-text">文章</span></a>
    </li></div>
  </div>



    <div class="post-content">
      
        <h3 id="Scrapy安装"><a href="#Scrapy安装" class="headerlink" title="Scrapy安装"></a>Scrapy安装</h3><p>今天在Ubuntu上安装python的爬虫框架Scrapy，遇到了一些问题。</p>
<h4 id="失败案例"><a href="#失败案例" class="headerlink" title="失败案例"></a>失败案例</h4><p>首先想用pip来安装Scrapy：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>出现了如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> Complete output from command python setup.py egg_info:</span><br><span class="line">    Couldn&apos;t find index page for &apos;incremental&apos; (maybe misspelled?)</span><br><span class="line">    No local packages or download links found for incremental&gt;=16.10.1</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">      File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">      File &quot;/tmp/pip-build-wIgIGQ/Twisted/setup.py&quot;, line 21, in &lt;module&gt;</span><br><span class="line">        setuptools.setup(**_setup[&quot;getSetupArgs&quot;]())</span><br><span class="line">      File &quot;/usr/lib/python2.7/distutils/core.py&quot;, line 111, in setup</span><br><span class="line">        _setup_distribution = dist = klass(attrs)</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/setuptools/dist.py&quot;, line 260, in __init__</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/setuptools/dist.py&quot;, line 284, in fetch_build_eggs</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/pkg_resources.py&quot;, line 563, in resolve</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/pkg_resources.py&quot;, line 799, in best_match</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/pkg_resources.py&quot;, line 811, in obtain</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/setuptools/dist.py&quot;, line 327, in fetch_build_egg</span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/setuptools/command/easy_install.py&quot;, line 434, in easy_install</span><br><span class="line">    </span><br><span class="line">      File &quot;build/bdist.linux-x86_64/egg/setuptools/package_index.py&quot;, line 475, in fetch_distribution</span><br><span class="line">    AttributeError: &apos;NoneType&apos; object has no attribute &apos;clone&apos;</span><br><span class="line">    </span><br><span class="line">    ----------------------------------------</span><br><span class="line">Command &quot;python setup.py egg_info&quot; failed with error code 1 in /tmp/pip-build-wIgIGQ/Twisted/</span><br></pre></td></tr></table></figure></p>
<p>google和百度了半天，都没有找到合适的解决方案：</p>
<p>参考了一个很像的<a href="https://www.cnblogs.com/hizf/p/7804711.html" target="_blank" rel="noopener">博客</a>，运行了<code>sudo -H pip install --upgrade setuptools</code>。</p>
<p>出现了如下的错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/basecommand.py&quot;, line 209, in main</span><br><span class="line">    status = self.run(options, args)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/commands/install.py&quot;, line 328, in run</span><br><span class="line">    wb.build(autobuilding=True)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/wheel.py&quot;, line 748, in build</span><br><span class="line">    self.requirement_set.prepare_files(self.finder)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/req/req_set.py&quot;, line 360, in prepare_files</span><br><span class="line">    ignore_dependencies=self.ignore_dependencies))</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/req/req_set.py&quot;, line 448, in _prepare_file</span><br><span class="line">    req_to_install, finder)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/req/req_set.py&quot;, line 397, in _check_skip_installed</span><br><span class="line">    finder.find_requirement(req_to_install, self.upgrade)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/index.py&quot;, line 442, in find_requirement</span><br><span class="line">    all_candidates = self.find_all_candidates(req.name)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/index.py&quot;, line 400, in find_all_candidates</span><br><span class="line">    for page in self._get_pages(url_locations, project_name):</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/index.py&quot;, line 545, in _get_pages</span><br><span class="line">    page = self._get_page(location)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/index.py&quot;, line 648, in _get_page</span><br><span class="line">    return HTMLPage.get_page(link, session=self.session)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/index.py&quot;, line 757, in get_page</span><br><span class="line">    &quot;Cache-Control&quot;: &quot;max-age=600&quot;,</span><br><span class="line">  File &quot;/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/sessions.py&quot;, line 480, in get</span><br><span class="line">    return self.request(&apos;GET&apos;, url, **kwargs)</span><br><span class="line">  File &quot;/usr/lib/python2.7/dist-packages/pip/download.py&quot;, line 378, in request</span><br><span class="line">    return super(PipSession, self).request(method, url, *args, **kwargs)</span><br><span class="line">  File &quot;/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/sessions.py&quot;, line 468, in request</span><br><span class="line">    resp = self.send(prep, **send_kwargs)</span><br><span class="line">  File &quot;/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/sessions.py&quot;, line 576, in send</span><br><span class="line">    r = adapter.send(request, **kwargs)</span><br><span class="line">  File &quot;/usr/share/python-wheels/CacheControl-0.11.5-py2.py3-none-any.whl/cachecontrol/adapter.py&quot;, line 46, in send</span><br><span class="line">    resp = super(CacheControlAdapter, self).send(request, **kw)</span><br><span class="line">  File &quot;/usr/share/python-wheels/requests-2.9.1-py2.py3-none-any.whl/requests/adapters.py&quot;, line 376, in send</span><br><span class="line">    timeout=timeout</span><br><span class="line">  File &quot;/usr/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/connectionpool.py&quot;, line 610, in urlopen</span><br><span class="line">    _stacktrace=sys.exc_info()[2])</span><br><span class="line">  File &quot;/usr/share/python-wheels/urllib3-1.13.1-py2.py3-none-any.whl/urllib3/util/retry.py&quot;, line 228, in increment</span><br><span class="line">    total -= 1</span><br><span class="line">TypeError: unsupported operand type(s) for -=: &apos;Retry&apos; and &apos;int&apos;</span><br></pre></td></tr></table></figure></p>
<p><strong>最终放弃</strong></p>
<h4 id="成功方案"><a href="#成功方案" class="headerlink" title="成功方案"></a>成功方案</h4><p>参考<a href="https://doc.scrapy.org/en/latest/intro/install.html" target="_blank" rel="noopener">官方文档</a>的另一种安装方式：<code>conda</code>。</p>
<p>要使用<code>conda</code>，需要安装<a href="https://docs.anaconda.com/anaconda/" target="_blank" rel="noopener"><code>Anaconda</code></a>或<a href="https://conda.io/docs/user-guide/install/index.html" target="_blank" rel="noopener"><code>Miniconda</code></a>。<br><code>Miniconda</code>是简化办的<code>Anaconda</code>。图方便安装了<code>Miniconda</code>。（安装方法：<a href="https://conda.io/docs/user-guide/install/linux.html" target="_blank" rel="noopener">https://conda.io/docs/user-guide/install/linux.html</a> ）</p>
<p>安装好<code>conda</code>之后，运行<code>conda install -c conda-forge scrapy</code>安装<code>Scrapy</code>。</p>
<p><strong>安装成功</strong>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy</span><br><span class="line">Scrapy 1.5.0 - no active project</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  scrapy &lt;command&gt; [options] [args]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  bench         Run quick benchmark test</span><br><span class="line">  fetch         Fetch a URL using the Scrapy downloader</span><br><span class="line">  genspider     Generate new spider using pre-defined templates</span><br><span class="line">  runspider     Run a self-contained spider (without creating a project)</span><br><span class="line">  settings      Get settings values</span><br><span class="line">  shell         Interactive scraping console</span><br><span class="line">  startproject  Create new project</span><br><span class="line">  version       Print Scrapy version</span><br><span class="line">  view          Open URL in browser, as seen by Scrapy</span><br><span class="line"></span><br><span class="line">  [ more ]      More commands available when run from project directory</span><br><span class="line"></span><br><span class="line">Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command</span><br></pre></td></tr></table></figure></p>
<h2 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h2><ol>
<li><a href="https://doc.scrapy.org/en/latest/intro/install.html" target="_blank" rel="noopener">Installation guide</a></li>
<li><a href="https://docs.anaconda.com/anaconda/" target="_blank" rel="noopener">Anaconda</a></li>
<li><a href="https://conda.io/docs/user-guide/install/index.html" target="_blank" rel="noopener">Miniconda</a></li>
<li><a href="https://conda.io/docs/user-guide/install/linux.html" target="_blank" rel="noopener">Conda: Installing on Linux</a></li>
<li><a href="https://www.cnblogs.com/hizf/p/7804711.html" target="_blank" rel="noopener">ubuntu 16.04 安装 scrapy 一个花了我5个小时的bug最终解决</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/22678445" target="_blank" rel="noopener">使用conda管理python环境</a></li>
</ol>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://sampwood.github.io">Sampwood</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://sampwood.github.io/2018/01/18/Scrapy框架安装/">https://sampwood.github.io/2018/01/18/Scrapy框架安装/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span>
      
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>



      
      
    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/web-crawler/">web crawler</a>
            
              <a href="/tags/environment/">environment</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2018/01/24/vue图片导入/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">vue图片导入</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    
    
      <a class="next" href="/2018/01/09/ts学习笔记/">
        <span class="next-text nav-default">ts学习笔记</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>


      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
  </div>


        </div>
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:sampwood@163.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/sampwood" class="iconfont icon-github" title="github"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
    

    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>



<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2019

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Sampwood</span>
  </span>
</div>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  
  

  



    
  



  
  





  
    <script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  

  
    <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.10.1"></script>

  </body>
</html>
